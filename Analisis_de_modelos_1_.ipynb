{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sebastian310/Rpa.pyautogui/blob/main/Analisis_de_modelos_1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd; from xgboost import XGBClassifier; import numpy as np; import xgboost as xgb; from sklearn.metrics import roc_auc_score; from sklearn.linear_model import LogisticRegression\n",
        "import warnings;warnings.filterwarnings(\"ignore\") # Se ignora advertencias de sklearn"
      ],
      "metadata": {
        "id": "9Q_YTLwgUnoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de datos y eliminación de filas con valores \"NA\"\n",
        "heart = pd.read_csv('Heart.csv')\n",
        "Dataset_SIN_NA = heart.dropna()\n",
        "\n",
        "print(\"Cantidad para muestra 80% es :\", round(len(Dataset_SIN_NA) * 0.8),\" y Cantidad para Testeo 20% es :\",round(len(Dataset_SIN_NA) * 0.2) )\n",
        "\n",
        "# Creación de variables dummies para variables Cualitativas y reemplazo de valores en variable objetivo\n",
        "randomised_heart = pd.get_dummies(Dataset_SIN_NA, columns=['ChestPain', 'Thal'], drop_first=False)\n",
        "randomised_heart['AHD'] = randomised_heart['AHD'].replace({'Yes': 1, 'No': 0})\n",
        "\n",
        "# distibuto 80% de datos entrenamiento y 20% de prueba\n",
        "heart_Train2, heart_Test2 = randomised_heart.loc[0:238], randomised_heart.loc[238:]\n",
        "\n",
        "# Asigno variables a Dataset de prueba\n",
        "columns_x_Var = ['Age', 'Sex', 'RestBP', 'Chol', 'Fbs', 'RestECG', 'MaxHR', 'ExAng', 'Oldpeak', 'Slope', 'ChestPain_asymptomatic', 'ChestPain_nonanginal', 'ChestPain_nontypical', 'ChestPain_typical','Thal_fixed', 'Thal_normal']\n",
        "x_entreno, x_prueba = heart_Train2[columns_x_Var], heart_Test2[columns_x_Var]\n",
        "y_entreno, y_prueba = heart_Train2['AHD'], heart_Test2['AHD']\n"
      ],
      "metadata": {
        "id": "KmCVFcCsNuBi",
        "outputId": "a1b288e0-bc2c-4587-a645-c0ba8f0ba46e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad para muestra 80% es : 238  y Cantidad para Testeo 20% es : 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 1- Haz validación cruzada 80%-20% utilizando regresión logística (sin penalización\n",
        "\n",
        "1.   Evalúa el test utilizando la AUC\n",
        "2.   Utiliza variables de input numéricas y categoricas (transformadas usando la funcion get_dummies\n",
        "3.   Hacer la validación cruzada aleatoriamente con 5-fold\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "idi9V0Z_NEO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(penalty='none')    # Creación del modelo de Regresión Logística\n",
        "\n",
        "X, y = pd.concat([x_entreno, x_prueba]), pd.concat([y_entreno, y_prueba]) # Variables de entrenamiento y prueba\n",
        "\n",
        "k_divisiones = 5  # Número de divisiones para la validación cruzada\n",
        "\n",
        "fold_size = len(X) // k_divisiones  # Tamaño de cada división\n",
        "\n",
        "auc_scores = []  # Lista para almacenar los puntajes AUC\n",
        "\n",
        "for i in range(k_divisiones):  # División de los datos en entrenamiento y prueba\n",
        "    X_test = X.iloc[i*fold_size:(i+1)*fold_size]\n",
        "    y_test = y.iloc[i*fold_size:(i+1)*fold_size]\n",
        "    X_train = X.drop(X_test.index)\n",
        "    y_train = y.drop(y_test.index)\n",
        "\n",
        "    clf.fit(X_train, y_train)  # Entrenamiento del modelo\n",
        "\n",
        "    y_prob = clf.predict_proba(X_test)[:, 1]                             # Calcula las probabilidades\n",
        "    auc_scores.append(roc_auc_score(y_test, y_prob))\n",
        "\n",
        "print('Promedio AUC: ', np.mean(auc_scores))\n"
      ],
      "metadata": {
        "id": "xfRXaoJ9jMJl",
        "outputId": "2b6a3c02-2d47-419c-9467-8e1b056bb0c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Promedio AUC:  0.893346174698167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejersicio 2 - Haz validación cruzada 80%-20% utilizando el modelo XGBoost  Con puntos  \n",
        "\n",
        "1.   Prueba diferentes combinaciones de los hyperparámetros max_depth y n_estimators.\n",
        "\n",
        "1.   Utiliza bucles for para evaluar la validación cruzada en cada uno de los hyperparámetros.\n",
        "2.   Utiliza variables de input numéricas y categoricas (transformadas usando la funcion get_dummies\n",
        "\n",
        "2.   Evalúa el test utilizando la AUC\n"
      ],
      "metadata": {
        "id": "lmeoaUZ0F_Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "X = randomised_heart[['Age', 'Sex', 'RestBP', 'Chol', 'Fbs', 'RestECG', 'MaxHR', 'ExAng', 'Oldpeak', 'Slope','ChestPain_asymptomatic', 'ChestPain_nonanginal', 'ChestPain_nontypical', 'ChestPain_typical','Thal_fixed', 'Thal_normal']]\n",
        "y = randomised_heart['AHD'].to_frame()            # Convierto esta serie a Dataframe para usar posteriormente Iloc\n",
        "\n",
        "tamano_fold = len(X) // 5   # Definir el tamaño de los pliegues\n",
        "\n",
        "for N_estimator in [10, 50, 100,150,200,]:\n",
        "    for depth in range(1, 8):\n",
        "        clf = XGBClassifier(n_estimators=N_estimator, learning_rate=1.0, max_depth=depth, random_state=0)\n",
        "\n",
        "        clf_scores = [] ; auc_scores = []  # designo listas\n",
        "\n",
        "        for i in range(5):\n",
        "\n",
        "            # Crear los índices de entrenamiento y prueba\n",
        "            test_indices = list(range(i * tamano_fold, (i + 1) * tamano_fold))\n",
        "            train_indices = list(set(range(len(X))) - set(test_indices))\n",
        "\n",
        "            # Crear los conjuntos de entrenamiento y prueba\n",
        "            X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
        "            y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
        "\n",
        "            # Entrenamiento del modelo\n",
        "            clf.fit(X_train, y_train)\n",
        "\n",
        "            # Calcula el score del clasificador\n",
        "            clf_score = clf.score(X_test, y_test)\n",
        "            clf_scores.append(clf_score)\n",
        "\n",
        "            # Calcula el AUC\n",
        "            y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "            auc = roc_auc_score(y_test, y_prob)\n",
        "            auc_scores.append(auc)\n",
        "\n",
        "        # Guardar los resultados en la lista \"Results\"\n",
        "        results.append({'N_estimator': N_estimator,'depth': depth,'clf_score': np.mean(clf_scores),'AUC': np.mean(auc_scores)})\n",
        "\n",
        "# Imprimir los resultados\n",
        "for result in results:\n",
        "    print('N_estimator:', result['N_estimator'], 'depth:', result['depth'], 'clf_score:', result['clf_score'], 'AUC:', result['AUC'])\n"
      ],
      "metadata": {
        "id": "IaIi-NEEHERY",
        "outputId": "cfe35610-dfc5-44a3-b529-9669d1b7e95b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N_estimator: 10 depth: 1 clf_score: 0.7898305084745763 AUC: 0.8852227799246053\n",
            "N_estimator: 10 depth: 2 clf_score: 0.7457627118644068 AUC: 0.8432825845814296\n",
            "N_estimator: 10 depth: 3 clf_score: 0.7593220338983051 AUC: 0.8290629480276147\n",
            "N_estimator: 10 depth: 4 clf_score: 0.7559322033898305 AUC: 0.831890096891193\n",
            "N_estimator: 10 depth: 5 clf_score: 0.7491525423728813 AUC: 0.8529189626499383\n",
            "N_estimator: 10 depth: 6 clf_score: 0.7389830508474577 AUC: 0.8410421052111003\n",
            "N_estimator: 10 depth: 7 clf_score: 0.7389830508474576 AUC: 0.8268085073271392\n",
            "N_estimator: 50 depth: 1 clf_score: 0.7898305084745763 AUC: 0.8873880054013371\n",
            "N_estimator: 50 depth: 2 clf_score: 0.7457627118644068 AUC: 0.8251746985012052\n",
            "N_estimator: 50 depth: 3 clf_score: 0.7525423728813558 AUC: 0.8362561490863362\n",
            "N_estimator: 50 depth: 4 clf_score: 0.742372881355932 AUC: 0.8268025842241638\n",
            "N_estimator: 50 depth: 5 clf_score: 0.7559322033898305 AUC: 0.8481822022705521\n",
            "N_estimator: 50 depth: 6 clf_score: 0.7559322033898306 AUC: 0.8376486222239837\n",
            "N_estimator: 50 depth: 7 clf_score: 0.7423728813559322 AUC: 0.8347364240877131\n",
            "N_estimator: 100 depth: 1 clf_score: 0.7830508474576272 AUC: 0.881040135880923\n",
            "N_estimator: 100 depth: 2 clf_score: 0.7389830508474576 AUC: 0.8158905001136402\n",
            "N_estimator: 100 depth: 3 clf_score: 0.7491525423728813 AUC: 0.8369996978570393\n",
            "N_estimator: 100 depth: 4 clf_score: 0.7491525423728813 AUC: 0.8312118134330888\n",
            "N_estimator: 100 depth: 5 clf_score: 0.7661016949152541 AUC: 0.8483971005124247\n",
            "N_estimator: 100 depth: 6 clf_score: 0.759322033898305 AUC: 0.8376738362675514\n",
            "N_estimator: 100 depth: 7 clf_score: 0.7423728813559322 AUC: 0.8380272115093159\n",
            "N_estimator: 150 depth: 1 clf_score: 0.8 AUC: 0.8768741679388803\n",
            "N_estimator: 150 depth: 2 clf_score: 0.7559322033898305 AUC: 0.8193823756204341\n",
            "N_estimator: 150 depth: 3 clf_score: 0.7423728813559322 AUC: 0.8383665193178867\n",
            "N_estimator: 150 depth: 4 clf_score: 0.7457627118644067 AUC: 0.832117184824065\n",
            "N_estimator: 150 depth: 5 clf_score: 0.7525423728813558 AUC: 0.8497930626569635\n",
            "N_estimator: 150 depth: 6 clf_score: 0.759322033898305 AUC: 0.8381454912377834\n",
            "N_estimator: 150 depth: 7 clf_score: 0.7457627118644068 AUC: 0.8408139823218506\n",
            "N_estimator: 200 depth: 1 clf_score: 0.8101694915254237 AUC: 0.8701567155487198\n",
            "N_estimator: 200 depth: 2 clf_score: 0.7423728813559322 AUC: 0.8197274420451726\n",
            "N_estimator: 200 depth: 3 clf_score: 0.7559322033898305 AUC: 0.8418714430821346\n",
            "N_estimator: 200 depth: 4 clf_score: 0.7457627118644068 AUC: 0.8309604203210498\n",
            "N_estimator: 200 depth: 5 clf_score: 0.7627118644067796 AUC: 0.8535228334484044\n",
            "N_estimator: 200 depth: 6 clf_score: 0.7559322033898305 AUC: 0.8392970872934393\n",
            "N_estimator: 200 depth: 7 clf_score: 0.7491525423728814 AUC: 0.842926606063981\n"
          ]
        }
      ]
    }
  ]
}