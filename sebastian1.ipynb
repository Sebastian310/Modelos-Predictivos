{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sebastian310/Modelos-Predictivos/blob/main/sebastian1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd; from xgboost import XGBClassifier; import numpy as np; import xgboost as xgb; from sklearn.metrics import roc_auc_score; from sklearn.linear_model import LogisticRegression\n"
      ],
      "metadata": {
        "id": "9Q_YTLwgUnoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de datos y eliminación de filas con valores \"NA\"\n",
        "heart = pd.read_csv('Heart.csv')\n",
        "Dataset_SIN_NA = heart.dropna()\n",
        "\n",
        "print(\"Cantidad para muestra 80% es :\", round(len(Dataset_SIN_NA) * 0.8),\" y Cantidad para Testeo 20% es :\",round(len(Dataset_SIN_NA) * 0.2) )\n",
        "\n",
        "# Creación de variables dummies para variables Cualitativas y reemplazo de valores en variable objetivo\n",
        "randomised_heart = pd.get_dummies(Dataset_SIN_NA, columns=['ChestPain', 'Thal'], drop_first=False)\n",
        "randomised_heart['AHD'] = randomised_heart['AHD'].replace({'Yes': 1, 'No': 0})\n",
        "\n",
        "# distibuto 80% de datos entrenamiento y 20% de prueba\n",
        "heart_Train2, heart_Test2 = randomised_heart.loc[0:238], randomised_heart.loc[238:]\n",
        "\n",
        "# Asigno variables a Dataset de prueba\n",
        "columns_x_Var = ['Age', 'Sex', 'RestBP', 'Chol', 'Fbs', 'RestECG', 'MaxHR', 'ExAng', 'Oldpeak', 'Slope', 'ChestPain_asymptomatic', 'ChestPain_nonanginal', 'ChestPain_nontypical', 'ChestPain_typical','Thal_fixed', 'Thal_normal']\n",
        "x_entreno, x_prueba = heart_Train2[columns_x_Var], heart_Test2[columns_x_Var]\n",
        "y_entreno, y_prueba = heart_Train2['AHD'], heart_Test2['AHD']\n"
      ],
      "metadata": {
        "id": "KmCVFcCsNuBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 1- Haz validación cruzada 80%-20% utilizando regresión logística (sin penalización\n",
        "\n",
        "1.   Evalúa el test utilizando la AUC\n",
        "2.   Utiliza variables de input numéricas y categoricas (transformadas usando la funcion get_dummies\n",
        "3.   Hacer la validación cruzada aleatoriamente con 5-fold\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "idi9V0Z_NEO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(penalty='none')    # Creación del modelo de Regresión Logística\n",
        "\n",
        "X, y = pd.concat([x_entreno, x_prueba]), pd.concat([y_entreno, y_prueba]) # Variables de entrenamiento y prueba\n",
        "\n",
        "k_divisiones = 5  # Número de divisiones para la validación cruzada\n",
        "\n",
        "fold_size = len(X) // k_divisiones  # Tamaño de cada división\n",
        "\n",
        "auc_scores = []  # Lista para almacenar los puntajes AUC\n",
        "\n",
        "for i in range(k_divisiones):  # División de los datos en entrenamiento y prueba\n",
        "    X_test = X.iloc[i*fold_size:(i+1)*fold_size]\n",
        "    y_test = y.iloc[i*fold_size:(i+1)*fold_size]\n",
        "    X_train = X.drop(X_test.index)\n",
        "    y_train = y.drop(y_test.index)\n",
        "\n",
        "    clf.fit(X_train, y_train)  # Entrenamiento del modelo\n",
        "\n",
        "    y_prob = clf.predict_proba(X_test)[:, 1]                             # Calcula las probabilidades\n",
        "    auc_scores.append(roc_auc_score(y_test, y_prob))\n",
        "\n",
        "print('Promedio AUC: ', np.mean(auc_scores))\n"
      ],
      "metadata": {
        "id": "xfRXaoJ9jMJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejersicio 2 - Haz validación cruzada 80%-20% utilizando el modelo XGBoost  Con puntos  \n",
        "\n",
        "1.   Prueba diferentes combinaciones de los hyperparámetros max_depth y n_estimators.\n",
        "\n",
        "1.   Utiliza bucles for para evaluar la validación cruzada en cada uno de los hyperparámetros.\n",
        "2.   Utiliza variables de input numéricas y categoricas (transformadas usando la funcion get_dummies\n",
        "\n",
        "2.   Evalúa el test utilizando la AUC\n"
      ],
      "metadata": {
        "id": "lmeoaUZ0F_Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "X = randomised_heart[['Age', 'Sex', 'RestBP', 'Chol', 'Fbs', 'RestECG', 'MaxHR', 'ExAng', 'Oldpeak', 'Slope','ChestPain_asymptomatic', 'ChestPain_nonanginal', 'ChestPain_nontypical', 'ChestPain_typical','Thal_fixed', 'Thal_normal']]\n",
        "y = randomised_heart['AHD'].to_frame()            # Convierto esta serie a Dataframe para usar posteriormente Iloc\n",
        "\n",
        "tamano_fold = len(X) // 5   # Definir el tamaño de los pliegues\n",
        "\n",
        "for N_estimator in [10, 50, 100,150,200,]:\n",
        "    for depth in range(1, 8):\n",
        "        clf = XGBClassifier(n_estimators=N_estimator, learning_rate=1.0, max_depth=depth, random_state=0)\n",
        "\n",
        "        clf_scores = [] ; auc_scores = []  # designo listas\n",
        "\n",
        "        for i in range(5):\n",
        "\n",
        "            # Crear los índices de entrenamiento y prueba\n",
        "            test_indices = list(range(i * tamano_fold, (i + 1) * tamano_fold))\n",
        "            train_indices = list(set(range(len(X))) - set(test_indices))\n",
        "\n",
        "            # Crear los conjuntos de entrenamiento y prueba\n",
        "            X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
        "            y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
        "\n",
        "            # Entrenamiento del modelo\n",
        "            clf.fit(X_train, y_train)\n",
        "\n",
        "            # Calcula el score del clasificador\n",
        "            clf_score = clf.score(X_test, y_test)\n",
        "            clf_scores.append(clf_score)\n",
        "\n",
        "            # Calcula el AUC\n",
        "            y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "            auc = roc_auc_score(y_test, y_prob)\n",
        "            auc_scores.append(auc)\n",
        "\n",
        "        # Guardar los resultados en la lista \"Results\"\n",
        "        results.append({'N_estimator': N_estimator,'depth': depth,'clf_score': np.mean(clf_scores),'AUC': np.mean(auc_scores)})\n",
        "\n",
        "# Imprimir los resultados\n",
        "for result in results:\n",
        "    print('N_estimator:', result['N_estimator'], 'depth:', result['depth'], 'clf_score:', result['clf_score'], 'AUC:', result['AUC'])\n"
      ],
      "metadata": {
        "id": "IaIi-NEEHERY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}